{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9e97c768",
   "metadata": {},
   "source": [
    "# MLP with PyTorch\n",
    "\n",
    "At this point, I know what MLPs are. We built one from scratch one of the previous folder. In this notebook, I want to implement an MLP again, but using PyTorch. This MLP will trained and evaluated on the MNIST dataset. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b95314f9",
   "metadata": {},
   "source": [
    "# The MNIST dataset\n",
    "\n",
    "Conveniently, the MNIST dataset is provided in PyTorch through the `torchvision` module, specifically through the `torchvision.dataset` module.\n",
    "\n",
    "In the following cell, I import the `torchvision` and `transforms` modules. The second module, as the name suggests, let us perform **common transformations on image data**. According to the [documentation](https://pytroch.org/vision/stable/transforms.html), Transforms are common image transformations available in the `torchvision.transforms` module.\n",
    "\n",
    "Another interesting feature is that transform operations can be **chained** together using `Compose`. We will use it in a couple of cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0c73c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a484c6d5",
   "metadata": {},
   "source": [
    "With the modules loaded, I want to load the dataset itself, and specify hyperparameters such as the size of the training and testing sets, and size of the mini-batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99200ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4af57f5e659b42cf8ce0265c3910f230",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST\\raw\\train-images-idx3-ubyte.gz to ./MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdf9f15c56854a4199e976ca4a6ded2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST\\raw\\train-labels-idx1-ubyte.gz to ./MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7ba60b4ceb74cb2ac54823d4f5f3a9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea3991a3f38f4fd4ac8429b4ed9e3511",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./MNIST\\raw\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x20cd8e5bfd0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_path = './'\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "mnist_train_dataset = torchvision.datasets.MNIST(\n",
    "    root=image_path, train=True,\n",
    "    transform=transform, download=True \n",
    ")\n",
    "\n",
    "mnist_test_dataset = torchvision.datasets.MNIST(\n",
    "    root=image_path, train=False,\n",
    "    transform=transform, download=True  \n",
    ")\n",
    "\n",
    "batch_size = 64\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "374c7899",
   "metadata": {},
   "source": [
    "Okay, what just happened? Since I want to download a dataset I created a `image_path` variable to store the path where I would like images to be stored, should they be downloaded or read from the filesystem, if I do not want the dataset to be downloaded.\n",
    "\n",
    "Then I move on create a `transform` pipeline. Ours only has one operation: `transform.ToTensor()`. The `ToTensor()` method (1)converts the pixel features into a floating type tensor and (2) normalizes the pixel from range [0, 255] to range [0, 1].\n",
    "\n",
    "After that is where I effectively create the training and testing dataset using the MNIST dataset. Since, I do not have it on my machine, I asked PyTorch to download it for me using the `download` paramater. I also want PyTorch to perform the `transform` we created earlier on the images being downloaded. I specify which operation to perform using the `transform` paramater.\n",
    "\n",
    "I finish with specifying the batch size, and manually setting the seed number of random number generation.\n",
    "\n",
    "With that being done, we cannot use the dataset just yet. We must pass the `Dataset` objects (`mnist_train_dataset` and `mnist_test_dataset`) into a dataset a `DataLoader` object. Remember through a `DataLoader`, we can properly iterate over a given dataset. Okay, let's do it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bf5fdb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_dl = DataLoader(mnist_train_dataset,\n",
    "                      batch_size, shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "41b962fe",
   "metadata": {},
   "source": [
    "We successfully created the data loader, with batches of 64 samples. Let's move on :)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7b769876",
   "metadata": {},
   "source": [
    "# Building the Model\n",
    "\n",
    "This section of the notebook is concerned with building the MLP to classify digits from the dataset we downloaded earlier.\n",
    "\n",
    "Our MLP will have:\n",
    "\n",
    "- an input layer\n",
    "- a hidden layer (32 activation units)\n",
    "- a hidden layer (16 activation units)\n",
    "- an output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e189465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_train_dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8493688a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
