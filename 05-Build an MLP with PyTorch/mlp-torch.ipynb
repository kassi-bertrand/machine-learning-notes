{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9e97c768",
   "metadata": {},
   "source": [
    "# MLP with PyTorch\n",
    "\n",
    "At this point, I know what MLPs are. We built one from scratch one of the previous folder. In this notebook, I want to implement an MLP again, but using PyTorch. This MLP will trained and evaluated on the MNIST dataset. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b95314f9",
   "metadata": {},
   "source": [
    "# The MNIST dataset\n",
    "\n",
    "Conveniently, the MNIST dataset is provided in PyTorch through the `torchvision` module, specifically through the `torchvision.dataset` module.\n",
    "\n",
    "In the following cell, I import the `torchvision` and `transforms` modules. The second module, as the name suggests, let us perform **common transformations on image data**. According to the [documentation](https://pytroch.org/vision/stable/transforms.html), Transforms are common image transformations available in the `torchvision.transforms` module.\n",
    "\n",
    "Another interesting feature is that transform operations can be **chained** together using `Compose`. We will use it in a couple of cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0c73c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a484c6d5",
   "metadata": {},
   "source": [
    "With the modules loaded, I want to load the dataset itself, and specify hyperparameters such as the size of the training and testing sets, and size of the mini-batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99200ea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1db9b400eb0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_path = './'\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "mnist_train_dataset = torchvision.datasets.MNIST(\n",
    "    root=image_path, train=True,\n",
    "    transform=transform, download=True \n",
    ")\n",
    "\n",
    "mnist_test_dataset = torchvision.datasets.MNIST(\n",
    "    root=image_path, train=False,\n",
    "    transform=transform, download=True  \n",
    ")\n",
    "\n",
    "batch_size = 64\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "374c7899",
   "metadata": {},
   "source": [
    "Okay, what just happened? Since I want to download a dataset I created a `image_path` variable to store the path where I would like images to be stored, should they be downloaded or read from the filesystem, if I do not want the dataset to be downloaded.\n",
    "\n",
    "Then I move on create a `transform` pipeline. Ours only has one operation: `transform.ToTensor()`. The `ToTensor()` method (1)converts the pixel features into a floating type tensor and (2) normalizes the pixel from range [0, 255] to range [0, 1].\n",
    "\n",
    "After that is where I effectively create the training and testing dataset using the MNIST dataset. Since, I do not have it on my machine, I asked PyTorch to download it for me using the `download` paramater. I also want PyTorch to perform the `transform` we created earlier on the images being downloaded. I specify which operation to perform using the `transform` paramater.\n",
    "\n",
    "I finish with specifying the batch size, and manually setting the seed number of random number generation.\n",
    "\n",
    "With that being done, we cannot use the dataset just yet. We must pass the `Dataset` objects (`mnist_train_dataset` and `mnist_test_dataset`) into a dataset a `DataLoader` object. Remember through a `DataLoader`, we can properly iterate over a given dataset. Okay, let's do it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bf5fdb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_dl = DataLoader(mnist_train_dataset,\n",
    "                      batch_size, shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "41b962fe",
   "metadata": {},
   "source": [
    "We successfully created the data loader, with batches of 64 samples. Let's move on :)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7b769876",
   "metadata": {},
   "source": [
    "# Building the Model\n",
    "\n",
    "This section of the notebook is concerned with building the MLP to classify digits from the dataset we downloaded earlier.\n",
    "\n",
    "Our MLP will have:\n",
    "\n",
    "- an input layer\n",
    "- a hidden layer (32 activation units)\n",
    "- a hidden layer (16 activation units)\n",
    "- an output layer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "55c2ac1a",
   "metadata": {},
   "source": [
    "Let's define the above layers in code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9b11fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_units = [32, 16] #number of activation units in EACH hidden layer\n",
    "image_size = mnist_train_dataset[0][0].shape #mnist_train_dataset[0] is a tuple (image[tensor], label)\n",
    "input_size = image_size[0] * image_size[1] * image_size[2] #number of channels * image height * image width\n",
    "\n",
    "# all the layers in the network \n",
    "all_layers = [nn.Flatten()]\n",
    "for hidden_unit  in hidden_units:\n",
    "    layer = nn.Linear(input_size, hidden_unit)\n",
    "    all_layers.append(layer)\n",
    "    all_layers.append(nn.ReLU())\n",
    "    input_size = hidden_unit\n",
    "\n",
    "all_layers.append(nn.Linear(hidden_units[-1], 10)) #output layer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4bcd48ea",
   "metadata": {},
   "source": [
    "We successfully created all the layers in the network, and we stored them all into the an array called: `all_layers`.\n",
    "\n",
    "Let's now create a model containing the layers we just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb5cb075",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(*all_layers)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4ea3e7a4",
   "metadata": {},
   "source": [
    "That's it. Done! Since each layer comes one after the other in an MLP, we use the `torch.nn.Sequential` module to place those layers *sequentially*.\n",
    "\n",
    "Let's print the model and see all the layers we inserted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f44aa88d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Flatten(start_dim=1, end_dim=-1)\n",
       "  (1): Linear(in_features=784, out_features=32, bias=True)\n",
       "  (2): ReLU()\n",
       "  (3): Linear(in_features=32, out_features=16, bias=True)\n",
       "  (4): ReLU()\n",
       "  (5): Linear(in_features=16, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a004cc03",
   "metadata": {},
   "source": [
    "When an image gets fed into the network $(1 \\times 28 \\times 28)$ the `Flatten` layer flattens the image to $(1 \\times 784)$.\n",
    "\n",
    "This flattened image goes through the first `Linear` layer. This layer computes the net input. It turns the $(1 \\times 784)$ to a $(1 \\times 32)$ matrix.\n",
    "\n",
    "Right after that, the values go through a `RELU` activation function.\n",
    "\n",
    "T"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
