{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf94f772",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks - Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b40ee4b",
   "metadata": {},
   "source": [
    "## A tidbit of history ðŸ“œ\n",
    "\n",
    "CNNs first appeared in the 1990s. The architecture was introduced by [Yann Lecun](https://en.wikipedia.org/wiki/Yann_LeCun) to classify handwritten digits from images. Due to the outstanding performance of CNNs on image classification tasks, this type of feedforward neural network gained a lot of attention and led to many improvements in the field of computer vision. That's the reason why I am learning about CNNs today."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123f78fb",
   "metadata": {},
   "source": [
    "## Why CNNs... and not our good old MLPs? ðŸ¤·\n",
    "\n",
    "- When using MLPs all pixels have to be colapsed to ONE axis before being fed in the network. So, instead of feeding a matrix, we feed in a vector. The consequence? our model loose spacial-related information in the input image.\n",
    "\n",
    "- Using a CNN instead of a fully connected layer substantially reduce the number of weights.\n",
    "\n",
    "- Using this architecture let us feed the image in the model as is, thus preserving all the information and let the network"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ee990100",
   "metadata": {},
   "source": [
    "## What is a CNN made of?\n",
    "\n",
    "Typically, CNNs are composed of different types of layers.\n",
    "\n",
    "1. **Convolutional** layers\n",
    "\n",
    "2. **Subsampling** layers\n",
    "\n",
    "3. **Fully connected** layers\n",
    "\n",
    "Let's explore each layer type."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d016bb9",
   "metadata": {},
   "source": [
    "### Convolutional layers\n",
    "\n",
    "**Convolutional layers** are, in my opinion, the most important of all the layers in a CNN. As a matter of fact, the architecture is named after them. I have a lot to learn on them. Let's get ready.\n",
    "\n",
    "A **discrete** convolution (or simply convolution) is a fundamental operation in a CNN. It is the operation that happens within convolutional layers. Here is a description of what a convolution is. \n",
    "\n",
    "Imagine you have two sequences of numbers, let's call them sequence A and sequence B. Discrete convolution takes each number from sequence A, one by one, and multiplies it with the corresponding number from sequence B. Then, it adds up all these multiplied results to create a new sequence, which we'll call the convolution result.\n",
    "\n",
    "To better visualize it, think of sequence B as a sliding window that moves across sequence A. At each position, the numbers in both sequences align, and we multiply them together. The convolution result represents the sum of all these multiplications as the window slides along the sequences.\n",
    "\n",
    "Discrete convolution is widely used in various fields, such as signal processing and image processing, to analyze and manipulate sets of data. It helps us find relationships, extract features, and perform operations like blurring, sharpening, or detecting patterns in signals or images.\n",
    "\n",
    "Personally, every time I think about the word \"convolution\" the image of sliding window pops up in my head. Here is an illustration of a 1-D discrete convolution. Notice: The filter is rotated before the convolution is computed.\n",
    "\n",
    "With a basic intuiton of a convolution is, let's learn some basic definition and notations. A discrete convolution for two vectors $x$ and $w$ is denoted by:\n",
    "\n",
    "$$\n",
    "y = x * w \\to y[i] = \\sum_{k=-\\infty}^{+\\infty} x[i - k] \\hspace{1mm} w[k]\n",
    "$$\n",
    "\n",
    "- Vector $x$ is the **input**, also called \"signal\"\n",
    "- Vector $w$ is known as the **filter**, or \"kernel\"\n",
    "- Vector $y$ is the result of the convolution. It is called is called a **feature map**.\n",
    "\n",
    "The first thing that I found weird was $-\\infty$ to $+\\infty$, mainly because finite feature vectors, at least in my relatively small machine learning experience. For example, if $x$ has 10 features with indices $0, 1, 2, \\dots, 8, 9,$ then indices â€“1 and 10 are out of bounds for $x$. Therefore, to correctly compute the summation shown in the preceding formula, it is assumed that **x and w are filled with zeros**. This will result in an output vector, $y$, that also has infinite size, with lots of zeros as well. Since this is not useful in practical situations, $x$ is padded only with a finite number of zeros.\n",
    "\n",
    "This process, I learned is called **zero-padding** or simply **padding**. The number of zeros padded on each side in denoted by the letter $p$.\n",
    "\n",
    "![Example of padding](./images/img-2.jpg)\n",
    "\n",
    "If we assume the original input, $x$, and filter, $w$, have $n$ and $m$ elements, respectively, where $m \\leq n$. \n",
    "Therefore, the padded vector, $x^{p}$, has size $n + 2p$. The practical formula for computing a discrete convolution will change to the following:\n",
    "\n",
    "$$\n",
    "y = x * w \\to y[i] = \\sum_{k=0}^{m - 1} x^{p}[i + m - k] \\hspace{1mm} w[k]\n",
    "$$\n",
    "\n",
    "$x$ is the original input and has $n$ elements.\n",
    "\n",
    "$w$ is the filter and has $m$ elements.\n",
    "\n",
    "$x^{p}$ is the padded vector and has size $n + 2p$\n",
    "\n",
    "The second thing that is worth mentioning is the indexing. $x$ and $w$ are indexed in *different directions* in the summation above. To make sure both $x$ and $w$ are indexed in the same directions, we can rotate the filter. If we assume $w^{r}$ to be the rotated filter, then the dot product becomes $x[i: 1+m].w^{r}$ to get one element $y[i]$. $x[i: 1+m]$ is a patch of $x$ withh size $m$. The operation is repeated like in a *sliding window* approach to get all the output elements. Here is an example:\n",
    "\n",
    "![1-D Discrete convolution](./images/img-1.png)\n",
    "\n",
    "In the previous example, the padding size is zero ($p = 0$). Notice, the rotated filter $w^{r}$ is shifted by two cells each time. This shift, in addition of the padding value, is another hyperparameter of a convolution. The shift I just described is called the **stride**, and is denoted $s$. In the previous example, $s = 2$.\n",
    "\n",
    "In practice, the padding is not always to zero. In fact, there are three ways to \"pad\" our input vector:\n",
    "\n",
    "1. **Full** mode: The padding parameter $p$ is set to $m - 1$. Full mode increases the dimensions of the output, so it is rarely used in CNN architectures.\n",
    "\n",
    "2. **Same** mode: The padding parameter $p$ is chosen so that the output vector has **the same size** as the input vector $x$. For this reason, $p$ is computed *according* to (1) the filter size, (2) the stride, and (3) the input size. This mode is the most commonly used. The output size $o$ of a convolution is given by the expression below. You can use it to determine the appropriate value of $p$. I let you try :) \n",
    "$$o = \\lfloor \\frac{n + 2p - m}{s} \\rfloor + 1$$\n",
    "\n",
    "3. **Valid** mode: Where padding is set to zero. It results in an output vector smaller than the input vector $x$. It is the case we explored in the example earlier.\n",
    "\n",
    "Before closing this long section on convolution layers, I would like to talk about **Cross-correlation**.\n",
    "\n",
    "A \"Cross-correlation\" (or simply correlation) between an input vector $x$ and a filter $w$ is denoted $y = x * w$ just like like a convolution, but unlike convolutions... the filter is **not** rotated. Most deep learning frameworks (including PyTorch) implement correlation, but refers to it as \"convolution.\"\n",
    "\n",
    "\\*Exhale\\*! We learned a lot of new terms and concepts. Let's now implement a basic 1-D convolution, like the one described in the image above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9cf3917",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#performing a discrete 1-D convolution\n",
    "import numpy as np\n",
    "\n",
    "def conv1d(x, w, p=0, s=1):\n",
    "    #1- Rotate filter\n",
    "    w_rot = np.array(w[::-1])\n",
    "    \n",
    "    #2- Pad input vector\n",
    "    x_padded = np.array(x)\n",
    "    if p > 0:\n",
    "        zero_pad = np.zeros(shape=p)\n",
    "        x_padded = np.concatenate([\n",
    "            zero_pad, x_padded, zero_pad\n",
    "        ])\n",
    "        \n",
    "    #3- Slide along the input.\n",
    "    #   From 0 to (input_length - filter size) + 1, and making 's' steps per iteration\n",
    "    res = []\n",
    "    for i in range(0, int(len(x_padded) - len(w_rot)) + 1, s):\n",
    "        res.append(\n",
    "            np.sum(x_padded[i: i + w_rot.shape[0]] * w_rot)\n",
    "        )\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf1ffb8",
   "metadata": {},
   "source": [
    "Let's test the `conv1d` function and use Numpy's `convolve` to double check our resutls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a7e12b0",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv1d Implementation: [5.0, 14.0, 16.0, 26.0, 24.0, 34.0, 19.0, 22.0]\n"
     ]
    }
   ],
   "source": [
    "x = [1, 3, 2, 4, 5, 6, 1, 3]\n",
    "w = [1, 0, 3, 1, 2]\n",
    "\n",
    "print('Conv1d Implementation:',\n",
    "     conv1d(x, w, p=2, s=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "323c0d6b",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy Results: [ 5 14 16 26 24 34 19 22]\n"
     ]
    }
   ],
   "source": [
    "print('NumPy Results:', \n",
    "      np.convolve(x, w, mode='same'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d70b4540",
   "metadata": {},
   "source": [
    "Results match!\n",
    "\n",
    "Before finishing and moving on to the next section, I would like to implement a 2D convolution. This is particularly important that I get an intuition for 2-D convolutions because the CNNs I will implement will be represented using 2-D matrices. I came across this GIF which I think illustrates the idea pretty nicely.\n",
    "\n",
    "![2-D convolution GIF](./images/img-gif-1.gif)\n",
    "\n",
    "It demonstrates the 2D convolution of an input matrix of size $(6 \\times 6)$ with a kernel (i.e. filter) $(3 \\times 3)$. The output of the 2D convolution is another matrix of size $(8 \\times 8)$. Because the size of the input and output matrices have the **same** size, can you tell what padding was used?ðŸ˜Š\n",
    "\n",
    "Let's consider another example. An input matrix of size $(3 \\times 3)$ is convolved with a kernel of size $(3 \\times 3)$ using padding $p = (1, 1)$ and stride $s = (2, 2)$.\n",
    "\n",
    "![2-D Convolution](./images/img-3.jpg)\n",
    "\n",
    "The result is the following $2 \\times 2$ matrix:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "4.6 & 1.6\\\\\n",
    "7.5 & 2.9\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Let's write a naive implementation for the 2-D convolution just like what we did for the 1-D convolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76c8219c",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.signal\n",
    "\n",
    "def conv2d(X, W, p=(0, 0), s=(1, 1)):    \n",
    "    #Rotate filter\n",
    "    W_rot = np.array(W)[::-1,::-1]\n",
    "    \n",
    "    #Copy input matrix\n",
    "    X_orig = np.array(X)\n",
    "    \n",
    "    #Compute dimension of padded matrix\n",
    "    n1 = X_orig.shape[0] + 2*p[0]\n",
    "    n2 = X_orig.shape[1] + 2*p[1]\n",
    "    \n",
    "    #Create a matrix full of zeros THEN fill in the old array in the new array\n",
    "    #The result is the original matrix, padded.\n",
    "    X_padded = np.zeros(shape=(n1, n2))\n",
    "    X_padded[p[0]:p[0]+X_orig.shape[0],\n",
    "             p[1]:p[1]+X_orig.shape[1]] = X_orig\n",
    "\n",
    "    res = []\n",
    "    for i in range(0,\n",
    "                   int((X_padded.shape[0] - W_rot.shape[0]))+1, s[0]):\n",
    "        res.append([])\n",
    "        \n",
    "        for j in range(0,\n",
    "                      int((X_padded.shape[1] - W_rot.shape[1])) + 1, s[1]):\n",
    "            X_sub = X_padded[i:i+W_rot.shape[0],\n",
    "                            j:j+W_rot.shape[1]]\n",
    "            \n",
    "            res[-1].append(np.sum(X_sub * W_rot))\n",
    "            \n",
    "    return(np.array(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53135e2",
   "metadata": {},
   "source": [
    "Let's test the `conv2d` function, and use scipy's `convolve2d` to double check results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30081af8",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d Implementation:\n",
      " [[11. 25. 32. 13.]\n",
      " [19. 25. 24. 13.]\n",
      " [13. 28. 25. 17.]\n",
      " [11. 17. 14.  9.]]\n"
     ]
    }
   ],
   "source": [
    "# REMEMBER: Numpy is by default 'row-major'\n",
    "X = [[1, 3, 2, 4], [5, 6, 1, 3], [1, 2, 0, 2], [3, 4, 3, 2]]\n",
    "W = [[1, 0, 3], [1, 2, 1], [0, 1, 1]]\n",
    "\n",
    "print('Conv2d Implementation:\\n',\n",
    "      conv2d(X, W, p=(1, 1), s=(1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af24d65b",
   "metadata": {
    "scrolled": true,
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SciPy Results:\n",
      " [[11 25 32 13]\n",
      " [19 25 24 13]\n",
      " [13 28 25 17]\n",
      " [11 17 14  9]]\n"
     ]
    }
   ],
   "source": [
    "print('SciPy Results:\\n',\n",
    "      scipy.signal.convolve2d(X, W, mode='same'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165ac22d",
   "metadata": {},
   "source": [
    "Interestingly, both results match!\n",
    "\n",
    "*Note: We implemented both `conv1d` and `conv2d` for education purposes; to get a sense of what is going on. Not to be used in real-word NN applications.*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "912acb20",
   "metadata": {},
   "source": [
    "To conclude my discussion on convolutional layers, I would like to talk about **images**, specifically what happens to an image going through a convolution layer in a CNN. I talked about convolutions, how to compute them, but now... I want to say how we are going to apply this to images.\n",
    "\n",
    "Images are made of pixels. But in case of colored (i.e. RGB) images, I know that the color of **EACH** pixel is obtained by *combining different amount* of the colors Red, Green, and Blue. A **color channel** refers to the set of values that represent the intensity of pixels for a specific color in an image. In RGB images, there are three color channels: red, green, and blue.\n",
    "\n",
    "As a result, colored images are often represented by 3-D matrices. Different Deep Learning frameworks will follow different conventions, but I know for sure that one dimension represents the width of the image, another represents the height of the image, and the remaining one represents the number of **color channel** in the image... which is our case is **3**.\n",
    "\n",
    "But the question now is:\n",
    "\n",
    "> **How do you convolve on a 3-D matrix?**\n",
    "\n",
    "Luckily, I came across this beautiful picture on Stack Overflow, which I think illustrates the idea pretty nicely.\n",
    "\n",
    "![3-D Convolution](./images/img-4.png)\n",
    "\n",
    "Let's talk about the picture a little bit. \n",
    "\n",
    "Consider that the input is a $6 \\times 6$ picture. The proportion of *green* in **EACH** pixel of the image is stored in the green matrix. The proportion of *blue* in **EACH** pixel of the image is stored in the blue matrix. And, the proportion of *red* in **EACH** pixel of the image is stored in the red-ish matrix. As you and I can see, this single image is stored as a $6 \\times 6 \\times 3$ (i.e. a 3-D matrix).\n",
    "\n",
    "Then we have the filters. Notice, we have 2 filters. In fact, we can have as many filters as you want. The size of the filter must be smaller than the dimension of the input image. But most importantly, the filters must have the *SAME* number of channels as the input image (3). Another way to put this would be this: If your input image is a 3-D matrix, your filters must also be 3-D matrices. If the image is a 1-D matrix, then the filters should also be 1-D matrices. Make sense? ðŸ¤”\n",
    "\n",
    "With the image, and the filters described let's talk about the convolution. The input matrix (i.e. image) is convolved with **EACH** filter, resulting in a *feature map* of size $(4 \\times 4)$. Since we have TWO filters, we end with TWO feature maps, each of size $(4 \\times 4)$. If the input matrix was convolved with 5 kernels, we'd have 5 feature maps as result.\n",
    "\n",
    "So, the resulting matrix after convolving the input image with both filters is of size $(4 \\times 4 \\times 2)$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e9f7ffe0",
   "metadata": {},
   "source": [
    "### Subsampling layers\n",
    "\n",
    "Subsampling layers usually come *after* convolutional layers in CNNs. These layers are where the **pooling** operation takes place. A pooling (i.e. subsampling) layer is usually denoted $P_{( n_1 \\times n_2)}$. The subscript denotes the number of adjacent pixels in each dimension where the pooling operation is performed. We refer to such a neighborhood as the *pooling size*.\n",
    "\n",
    "Typically two forms of pooling operations take place in CNNs: **max-pooling** and **mean-pooling**. Max-pooling takes the maximum value from a neighborhood of pixels, while mean-pooling computes their average. Here is an image that illustrates the point nicely:\n",
    "\n",
    "![Pooling example](./images/img-5.jpg)\n",
    "\n",
    "But why is pooling useful? The advantage is twofold:\n",
    "\n",
    "1. Pooling reduces the size of features, which results in higher computational efficiency.\n",
    "\n",
    "2. Pooling (max-pooling) introduces a local invariance. This means that small changes in a local neighborhood do not change the result of max-pooling. It helps with generating features that more resistant to noise in the input data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da4b98c",
   "metadata": {},
   "source": [
    "### Fully-connected layers\n",
    "\n",
    "A fully-connected layers is when every single activation unit in one layer is connected to *ALL* activation units in the following layer. An MLP is an example of multiple fully-conncected layer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
