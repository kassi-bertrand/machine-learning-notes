{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf94f772",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks - Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b40ee4b",
   "metadata": {},
   "source": [
    "## A tidbit of history ðŸ“œ\n",
    "\n",
    "CNNs first appeared in the 1990s. The architecture was introduced by [Yann Lecun](https://en.wikipedia.org/wiki/Yann_LeCun) to classify handwritten digits from images. Due to the outstanding performance of CNNs on image classification tasks, this type of feedforward neural network gained a lot of attention and led to many improvements in the field of computer vision. That's the reason why I am learning about CNNs today."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123f78fb",
   "metadata": {},
   "source": [
    "## Why CNNs... and not our good old MLPs? ðŸ¤·\n",
    "\n",
    "- When using MLPs all pixels have to be colapsed to ONE axis before being fed in the network. So, instead of feeding a matrix, we feed in a vector. The consequence? our model loose spacial-related information in the input image.\n",
    "\n",
    "- Using a CNN instead of a fully connected layer substantially reduce the number of weights.\n",
    "\n",
    "- Using this architecture let us feed the image in the model as is, thus preserving all the information and let the network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee990100",
   "metadata": {},
   "source": [
    "## What is a CNN made of?\n",
    "\n",
    "Typically, CNNs are composed of different types of layers.\n",
    "\n",
    "1. **Convolutional** layers\n",
    "\n",
    "2. **Subsampling** layers\n",
    "\n",
    "3. **Pooling** layers\n",
    "\n",
    "Let's explore each layer type."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d016bb9",
   "metadata": {},
   "source": [
    "### Convolutional layers\n",
    "\n",
    "**Convolutional layers** are, in my opinion, the most important of all the layers in a CNN. As a matter of fact, the architecture is named after them. I have a lot to learn on them. Let's get ready.\n",
    "\n",
    "A **discrete** convolution (or simply convolution) is a fundamental operation in a CNN. It is the operation that happens within convolutional layers. Here is a description of what a convolution is. \n",
    "\n",
    "Imagine you have two sequences of numbers, let's call them sequence A and sequence B. Discrete convolution takes each number from sequence A, one by one, and multiplies it with the corresponding number from sequence B. Then, it adds up all these multiplied results to create a new sequence, which we'll call the convolution result.\n",
    "\n",
    "To better visualize it, think of sequence B as a sliding window that moves across sequence A. At each position, the numbers in both sequences align, and we multiply them together. The convolution result represents the sum of all these multiplications as the window slides along the sequences.\n",
    "\n",
    "Discrete convolution is widely used in various fields, such as signal processing and image processing, to analyze and manipulate sets of data. It helps us find relationships, extract features, and perform operations like blurring, sharpening, or detecting patterns in signals or images.\n",
    "\n",
    "Personally, every time I think about the word \"convolution\" the image of sliding window pops up in my head. Here is an illustration of a 1-D discrete convolution. Notice: The filter is rotated before the convolution is computed.\n",
    "\n",
    "With a basic intuiton of a convolution is, let's learn some basic definition and notations. A discrete convolution for two vectors $x$ and $w$ is denoted by:\n",
    "\n",
    "$$\n",
    "y = x * w \\to y[i] = \\sum_{k=-\\infty}^{+\\infty} x[i - k] \\hspace{1mm} w[k]\n",
    "$$\n",
    "\n",
    "- Vector $x$ is the **input**, also called \"signal\"\n",
    "- Vector $w$ is known as the **filter**, or \"kernel\"\n",
    "- Vector $y$ is the result of the convolution. It is called is called a **feature map**.\n",
    "\n",
    "The first thing that I found weird was $-\\infty$ to $+\\infty$, mainly because finite feature vectors, at least in my relatively small machine learning experience. For example, if $x$ has 10 features with indices $0, 1, 2, \\dots, 8, 9,$ then indices â€“1 and 10 are out of bounds for $x$. Therefore, to correctly compute the summation shown in the preceding formula, it is assumed that **x and w are filled with zeros**. This will result in an output vector, $y$, that also has infinite size, with lots of zeros as well. Since this is not useful in practical situations, $x$ is padded only with a finite number of zeros.\n",
    "\n",
    "This process, I learned is called **zero-padding** or simply **padding**. The number of zeros padded on each side in denoted by the letter $p$.\n",
    "\n",
    "![Example of padding](./images/img-2.jpg)\n",
    "\n",
    "If we assume the original input, $x$, and filter, $w$, have $n$ and $m$ elements, respectively, where $m \\leq n$. \n",
    "Therefore, the padded vector, $x^{p}$, has size $n + 2p$. The practical formula for computing a discrete convolution will change to the following:\n",
    "\n",
    "$$\n",
    "y = x * w \\to y[i] = \\sum_{k=0}^{m - 1} x^{p}[i + m - k] \\hspace{1mm} w[k]\n",
    "$$\n",
    "\n",
    "$x$ is the original input and has $n$ elements.\n",
    "\n",
    "$w$ is the filter and has $m$ elements.\n",
    "\n",
    "$x^{p}$ is the padded vector and has size $n + 2p$\n",
    "\n",
    "The second thing that is worth mentioning is the indexing. $x$ and $w$ are indexed in *different directions* in the summation above. To make sure both $x$ and $w$ are indexed in the same directions, we can rotate the filter. If we assume $w^{r}$ to be the rotated filter, then the dot product becomes $x[i: 1+m].w^{r}$ to get one element $y[i]$. $x[i: 1+m]$ is a patch of $x$ withh size $m$. The operation is repeated like in a *sliding window* approach to get all the output elements. Here is an example:\n",
    "\n",
    "![1-D Discrete convolution](./images/img-1.png)\n",
    "\n",
    "In the previous example, the padding size is zero ($p = 0$). Notice, the rotated filter $w^{r}$ is shifted by two cells each time. This shift, in addition of the padding value, is another hyperparameter of a convolution. The shift I just described is called the **stride**, and is denoted $s$. In the previous example, $s = 2$.\n",
    "\n",
    "In practice, the padding is not always to zero. In fact, there are three ways to \"pad\" our input vector:\n",
    "\n",
    "1. **Full** mode: The padding parameter $p$ is set to $m - 1$. Full mode increases the dimensions of the output, so it is rarely used in CNN architectures.\n",
    "\n",
    "2. **Same** mode: The padding parameter $p$ is chosen so that the output vector has **the same size** as the input vector $x$. For this reason, $p$ is computed *according* to (1) the filter size, (2) the stride, and (3) the input size. This mode is the most commonly used. The output size $o$ of a convolution is given by the expression below. You can use it to determine the appropriate value of $p$. I let you try :) \n",
    "$$o = \\lfloor \\frac{n + 2p - m}{s} \\rfloor + 1$$\n",
    "\n",
    "3. **Valid** mode: Where padding is set to zero. It results in an output vector smaller than the input vector $x$. It is the case we explored in the example earlier.\n",
    "\n",
    "Before closing this long section on convolution layers, I would like to talk about **Cross-correlation**.\n",
    "\n",
    "A \"Cross-correlation\" (or simply correlation) between an input vector $x$ and a filter $w$ is denoted $y = x * w$ just like like a convolution, but unlike convolutions... the filter is **not** rotated. Most deep learning frameworks (including PyTorch) implement correlation, but refers to it as \"convolution.\"\n",
    "\n",
    "\\*Exhale\\*! We learned a lot of new terms and concepts. Let's now implement a basic 1-D convolution, like the one described in the image above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cf3917",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#performing a discrete 1-D convolution\n",
    "def conv1d(x, w, s, p):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70b4540",
   "metadata": {},
   "source": [
    "Before finishing and moving on to other layers, let's implement a 2D convolution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f7ffe0",
   "metadata": {},
   "source": [
    "### Subsampling layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da4b98c",
   "metadata": {},
   "source": [
    "### Fully-connected layers\n",
    "\n",
    "A fully-connected layers is when every single activation unit in one layer is connected to *ALL* activation units in the following layer. An MLP is an example of multiple fully-conncected layer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
