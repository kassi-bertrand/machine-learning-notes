{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf94f772",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks - Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b40ee4b",
   "metadata": {},
   "source": [
    "## A tidbit of history ðŸ“œ\n",
    "\n",
    "CNNs first appeared in the 1990s. The architecture was introduced by [Yann Lecun](https://en.wikipedia.org/wiki/Yann_LeCun) to classify handwritten digits from images. Due to the outstanding performance of CNNs on image classification tasks, this type of feedforward neural network gained a lot of attention and led to many improvements in the field of computer vision. That's the reason why I am learning about CNNs today."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123f78fb",
   "metadata": {},
   "source": [
    "## Why CNNs... and not our good old MLPs? ðŸ¤·\n",
    "\n",
    "- When using MLPs all pixels have to be colapsed to ONE axis before being fed in the network. So, instead of feeding a matrix, we feed in a vector. The consequence? our model loose spacial-related information in the input image.\n",
    "\n",
    "- Using a CNN instead of a fully connected layer substantially reduce the number of weights.\n",
    "\n",
    "- Using this architecture let us feed the image in the model as is, thus preserving all the information and let the network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee990100",
   "metadata": {},
   "source": [
    "## What is a CNN made of?\n",
    "\n",
    "Typically, CNNs are composed of different types of layers.\n",
    "\n",
    "1. **Convolutional** layers\n",
    "\n",
    "2. **Subsampling** layers\n",
    "\n",
    "3. **Pooling** layers\n",
    "\n",
    "Let's explore each layer type."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d016bb9",
   "metadata": {},
   "source": [
    "### Convolutional layers\n",
    "\n",
    "**Convolutional layers** are, in my opinion, the most important of all the layers in a CNN. As a matter of fact, the architecture is named after them.\n",
    "\n",
    "A **discrete** convolution (or simply convolution) is a fundamental operation in a CNN. It is the operation that happens within convolutional layers. Here is a description of what a convolution is. \n",
    "\n",
    "Imagine you have two sequences of numbers, let's call them sequence A and sequence B. Discrete convolution takes each number from sequence A, one by one, and multiplies it with the corresponding number from sequence B. Then, it adds up all these multiplied results to create a new sequence, which we'll call the convolution result.\n",
    "\n",
    "To better visualize it, think of sequence B as a sliding window that moves across sequence A. At each position, the numbers in both sequences align, and we multiply them together. The convolution result represents the sum of all these multiplications as the window slides along the sequences.\n",
    "\n",
    "![1-D Discrete convolution](./images/img-1.png)\n",
    "\n",
    "Discrete convolution is widely used in various fields, such as signal processing and image processing, to analyze and manipulate sets of data. It helps us find relationships, extract features, and perform operations like blurring, sharpening, or detecting patterns in signals or images.\n",
    "\n",
    "Personally, every time I think about the word \"convolution\" the image of sliding window pops up in my head. Here is an illustration of a 1-D discrete convolution. Notice: The filter is rotated before the convolution is computed.\n",
    "\n",
    "With a basic intuiton of a convolution is, let's learn some basic definition and notations. A discrete convolution for two vectors $x$ and $w$ is denoted by:\n",
    "\n",
    "$$\n",
    "y = x * w \\to y[i] = \\sum_{k=-\\infty}^{+\\infty} x[i - k] \\hspace{1mm} w[k]\n",
    "$$\n",
    "\n",
    "- Vector $x$ is the **input**, also called \"signal\"\n",
    "- Vector $w$ is known as the **filter**, or \"kernel\"\n",
    "- Vector $y$ is the result of the convolution. It is called is called a **feature map**.\n",
    "\n",
    "The first thing that I found weird was $-\\infty$ to $+\\infty$, mainly because finite feature vectors, at least in my relatively small machine learning experience. For example, if $x$ has 10 features with indices $0, 1, 2, \\dots, 8, 9,$ then indices â€“1 and 10 are out of bounds for $x$. Therefore, to correctly compute the summation shown in the preceding formula, it is assumed that **x and w are filled with zeros**. This will result in an output vector, $y$, that also has infinite size, with lots of zeros as well. Since this is not useful in practical situations, $x$ is padded only with a finite number of zeros.\n",
    "\n",
    "This process, I learned is called **zero-padding** or simply **padding**. The number of zeros padded on each side in denoted by the letter $p$.\n",
    "\n",
    "![Example of padding](./images/img-2.jpg)\n",
    "\n",
    "If we assume the original input, $x$, and filter, $w$, have $n$ and $m$ elements, respectively, where $m \\leq n$. \n",
    "Therefore, the padded vector, $x^{p}$, has size $n + 2p$. The practical formula for computing a discrete convolution will change to the following:\n",
    "\n",
    "$$\n",
    "y = x * w \\to y[i] = \\sum_{k=0}^{m - 1} x^{p}[i + m - k] \\hspace{1mm} w[k]\n",
    "$$\n",
    "\n",
    "$x$ is the original input and has $n$ elements.\n",
    "\n",
    "$w$ is the filter and has $m$ elements.\n",
    "\n",
    "$x^{p}$ is the padded vector and has size $n + 2p$\n",
    "\n",
    "TODO: Talk about types of padding\n",
    "\n",
    "Let's now to implement a basic 1-D convolution, like the one described in the image above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cf3917",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#performing a discrete 1-D convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70b4540",
   "metadata": {},
   "source": [
    "Before finishing and moving on to other layers, let's implement a 2D convolution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f7ffe0",
   "metadata": {},
   "source": [
    "### Subsampling layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da4b98c",
   "metadata": {},
   "source": [
    "### Fully-connected layers\n",
    "\n",
    "A fully-connected layers is when every single activation unit in one layer is connected to *ALL* activation units in the following layer. An MLP is an example of multiple fully-conncected layer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
