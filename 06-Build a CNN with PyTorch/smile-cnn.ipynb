{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e01d067",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks - Smile Classifier\n",
    "\n",
    "In this notebook, I implement a CNN to classify face images based on smiles. I also explore data augmentation techiniques to enhance the model's performance. Let's jump in right away and load the celebA dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86efb7bd",
   "metadata": {},
   "source": [
    "# Loading the CelebA dataset\n",
    "\n",
    "CelebFaces Attributes Dataset, or CelebA for short, is an image dataset that identifies celebrity face attributes. It contains 202,599 face images across five landmark locations, with 40 binary attribute annotations for each image. \n",
    "\n",
    "Tought the dataset is available through the PyTorch's `torchvision` module, the link appears to be unstable. So, I downloaded the dataset manually using this [link](https://drive.google.com/file/d/1m8-EBPgi5MRubrm6iQjafK2QMHDBMSfJ/view?usp=sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02ad3253",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "image_path = './dataset'\n",
    "\n",
    "#Load training partition of the dataset\n",
    "celeba_train_dataset = torchvision.datasets.CelebA(\n",
    "    root=image_path, split='train',\n",
    "    target_type='attr', download=False\n",
    ")\n",
    "\n",
    "#Load validation partition of the dataset\n",
    "celeba_valid_dataset = torchvision.datasets.CelebA(\n",
    "    root=image_path, split='valid',\n",
    "    target_type='attr', download=False\n",
    ")\n",
    "\n",
    "#Load testing partition of the dataset\n",
    "celeba_valid_dataset = torchvision.datasets.CelebA(\n",
    "    root=image_path, split='test',\n",
    "    target_type='attr', download=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffd47f9",
   "metadata": {},
   "source": [
    "# Data augmentation\n",
    "\n",
    "**Data augmentation** refers to a set of techniques for dealing with cases where the training data is limited. Those techniques let us modify or even synthesize more data to bring more variation in the dataset which is good.\n",
    "\n",
    "To augment our dataset, we need to perform \"transformations\" on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "93730c41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([162770, 40])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "celeba_train_dataset.attr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea4aa6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
