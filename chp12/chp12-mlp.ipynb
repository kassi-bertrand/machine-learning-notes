{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bcdc3a1",
   "metadata": {},
   "source": [
    "# Implementing a Multilayer Artificial Neural Network from Sractch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0785f85",
   "metadata": {},
   "source": [
    "## Introducting the multiplayer neural network architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b564a3",
   "metadata": {},
   "source": [
    "We are going to start our exploration of Neural networks with a **M**ulti**L**ayer **P**erceptron (MLP). We'll use it to learn how to connect multiple single neurons. The following picture illustrates an MLP consisting of **three** layers:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2aff359",
   "metadata": {},
   "source": [
    "![mlp](etc/mlp.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626bff43",
   "metadata": {},
   "source": [
    "The above MLP has one:\n",
    "\n",
    "- Input Layer (1st layer)\n",
    "- Hidden Layer (2nd layer)\n",
    "- Output Layer (3rd layer)\n",
    "\n",
    "And notice, our MLP is **fully connected**. It means that each unit in the input layer is **connected to all** units in the hidden layer, and each units in the hidden layer is **connected to all** units in the output layer. If the network had _more than one_ hidden layer, we would call it a **deep artificial Neural Network (NN)**. And the field of **Deep Learning** is concerned with the development algorithm to help us train such structures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffef7c15",
   "metadata": {},
   "source": [
    "Now, let's define how we will refer to elements in our neural network:\n",
    "\n",
    "- We denote the $i^{th}$ activation unit in the $l^{th}$ layer: $a_i^{(l)}$\n",
    "- We denote the connection between the $k^{th}$ unit in layer $l - 1$ to the $j^{th}$ unit in layer $l$ as: $w_{k,j}^{l}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb847730",
   "metadata": {},
   "source": [
    "The book denotes the weight matrix that connects the input to the hidden layer as: **$W^{(h)}$** and the weight matrix that connects the hidden layer to the output layer as: **$W^{(out)}$**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e497a2f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Wait, what **Weight matrix?!**\n",
    "\n",
    "Okay, let me walk you through how to derive $W^{(h)}$ and you can try to do the same for $W^{(out)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd774c3",
   "metadata": {},
   "source": [
    "Let's say we have a data set of only **ONE** training example, and we want to \"forward\" propagate that one input from the input layer (in) to the hidden layer (h). To do that, we have to compute $a_1^{(h)}$, $a_2^{(h)}$, $\\dots$, $a_d^{(h)}$. For instance,\n",
    "\n",
    "$a_1^{(h)} = \\phi(z_1^{(h)})$\n",
    "\n",
    "$z_1^{(h)} = a_0^{(in)} w_{0,1}^{(h)} + a_1^{(in)} w_{1,1}^{(h)} + \\dots + a_m^{(in)} w_{m,1}^{(h)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d68d68",
   "metadata": {},
   "source": [
    "Now consider the following matrix for $z^{(h)}$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aa7df8b6",
   "metadata": {},
   "source": [
    "![demo-2.jpg](etc/demo.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66da994c",
   "metadata": {},
   "source": [
    "Notice, the weight matrix $W^{(h)}$ is an $m \\times d$ matrix where $d$ is the number of units in the hidden layer and $m$ is the number of units in the input layer, including the bias unit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7b551a",
   "metadata": {},
   "source": [
    "As you can see, our training example is being multiplied by that weight matrix, to compute its net input vector $Z^{(h)}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a41a44",
   "metadata": {},
   "source": [
    "$Z^{(h)} = a^{(in)}W^{(h)}$\n",
    "\n",
    "$a^{(h)} = \\phi(Z^{(h)})$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bcc2f9",
   "metadata": {},
   "source": [
    "Here $a^{(in)}$, is our training example (an $1 \\times m$ matrix). And since $W^{(h)}$ is an $m \\times d$ matrix, the resulting net input vector $Z^{(h)}$ is an $1 \\times d$ row matrix. That net input vector is then passed to the activation function to compute $a^{(h)}$ which is $1 \\times d$ matrix. Now, we can generalize this computation to all $n$ example in the training dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d98fb4",
   "metadata": {},
   "source": [
    "$Z^{(h)} = A^{(in)}W^{(h)}$. Here, $A^{(in)}$ is an $n \\times m$ matrix.\n",
    "\n",
    "**Each** training example (row) in the matrix is multiplied by the weight matrix. This multiplication happens through the matrix-matrix multiplication of $A^{(in)}$ and $W^{(h)}$ because each row of $A^{(in)}$ gets multiplied to $W^{(h)}$. \n",
    "\n",
    "This matrix-matrix multiplication results in an $n \\times d$, net input matrix $Z^{(h)}$; where the $i^{(th)}$ row in $Z^{(h)}$ is the result of the matrix-vector multiplication of the $i^{(th)}$ training example and the weight matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ddc359",
   "metadata": {},
   "source": [
    "Finally, we apply the function $\\phi(\\bullet)$ to each value in the net input matrix to get the $n \\times d$ **activation** matrix. \n",
    "\n",
    "$A^{(h)} = \\phi(Z^{(h)})$\n",
    "\n",
    "The $i^{(th)}$ row in the activation matrix contains the values the activation units in the hidden layer will contains after the $i^{th}$ training example forward propagates :)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4e33158a",
   "metadata": {},
   "source": [
    "Similarly, we can write the activation of the **output layer** in vectorized form for multiple examples:\n",
    "\n",
    "$Z^{(out)} = A^{(h)}W^{(out)}$ and $A^{(out)} = \\phi(Z^{(out)})$ where $A^{(out)}$ is an $n \\times t$ matrix.\n",
    "\n",
    "**Challenge**: Can you derive $W^{(out)}$ on your own? Here is mine, in case you find it difficult. As you can see on the following image, the $W^{(out)}$ is an $d \\times t$ matrix."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b0895aab",
   "metadata": {},
   "source": [
    "![demo W_out](etc/demo-w_out.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f62f666",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Ok, cool. But why did we use those matrices?\n",
    "\n",
    "For code effeciency and readability. We used our basic linear algebra skills to write the computations in a more compact way, so we do not use computationally expensive Python `for` loops. It also helps us delegate those computations to a GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e793c65d",
   "metadata": {},
   "source": [
    "## Classifying handwritten digits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6e7a2d",
   "metadata": {},
   "source": [
    "Let's implement and train our first multilayer NN to classify handwritten digits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a19075",
   "metadata": {},
   "source": [
    "### Obtaining and preparing the MINIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b47ebe",
   "metadata": {},
   "source": [
    "The dataset is freely available on [Yann Lecun's website](http://yann.lecun.com/exdb/mnist/). It consists of the following four parts:\n",
    "\n",
    "1. **Training dataset images**: train-images-idx3-ubyte.gz (60,000 examples)\n",
    "2. **Training dataset labels**: train-labels-idx1-ubyte.gz (60,000 labels)\n",
    "3. **Test dataset images**: t10k-images-idx3-ubyte.gz (10,000 examples)\n",
    "4. **Test dataset labels**: t10k-labels-idx1-ubyte.gz (10,000 labels)\n",
    "\n",
    "Each part is in its own archive file, and must be unzipped."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5f102c",
   "metadata": {},
   "source": [
    "With the dataset unzipped, we need to read the images and the labels into NumPy arrays. Both are stored as _binary_ files. We acheive this using the `load_mnist` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b50a7630",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import struct\n",
    "import numpy as np\n",
    "\n",
    "def load_mnist(path, kind='train'):\n",
    "    \"\"\"Load MNIST dataset from 'path' \"\"\"\n",
    "    \n",
    "    images_path = os.path.join(path, '%s-images-idx3-ubyte' %kind) #Notice, it is a formatted string\n",
    "    labels_path = os.path.join(path, '%s-labels-idx1-ubyte' %kind)\n",
    "    \n",
    "    #Read in the labels\n",
    "    with open(labels_path, 'rb') as lbpath:\n",
    "        magic, n = struct.unpack('>II', lbpath.read(8)) #Read the first 64 bits (8 bytes)\n",
    "        labels = np.fromfile(lbpath, dtype=np.uint8) # Construct array from Reading bytes one at a time\n",
    "        \n",
    "    #Read in the images\n",
    "    with open(images_path, 'rb') as imgpath:\n",
    "        magic, num, rows, cols = struct.unpack('>IIII', imgpath.read(16))\n",
    "        images = np.fromfile(imgpath, dtype=np.uint8).reshape(len(labels), 784) #Read all the pixels into ONE large array, then reshape it into a 60,000 x 784 matrix\n",
    "        images = ((images / 255.) - 0.5) * 2 #Normalize pixels between -1 to 1\n",
    "        \n",
    "    \n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f93843",
   "metadata": {},
   "source": [
    "It is common practice to have pixels fall in the $[-1, 1]$ range and centered at 0. It usually works well in practice, Sebastian Raschka says in his Python Machine Learning book."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ca706e",
   "metadata": {},
   "source": [
    "With the `load_mnist` helper written, let's load the MNNIST dataset. In my case, the MNIST dataset is within the `dataset` folder which I added to my `.gitignore` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26f7edf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 60000, Columns: 784\n"
     ]
    }
   ],
   "source": [
    "#X_train = the training set, \n",
    "#y_train = label for each training example in X_train\n",
    "X_train, y_train = load_mnist('./dataset', kind='train')\n",
    "\n",
    "#X_train dimensions\n",
    "print('Rows: %d, Columns: %d' %(X_train.shape[0], X_train.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61ea1d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 10000, Columns: 784\n"
     ]
    }
   ],
   "source": [
    "#X_test = the testing set (part of the dataset set aside to test the NN)\n",
    "#y_test = label for each training example in X_test\n",
    "X_test, y_test = load_mnist('./dataset', kind='t10k')\n",
    "\n",
    "#X_test dimensions\n",
    "print('Rows: %d, Columns: %d' %(X_test.shape[0], X_test.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0979a092",
   "metadata": {},
   "source": [
    "As we can see, the training set and the testing set contain 60,000 and 10,000 examples respectively. And each example has 784 features, where each feature is a pixel :). Since we are dealing with $28 \\times 28$ images, we have $784$ pixels in total."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8108b74a",
   "metadata": {},
   "source": [
    "Let's plot some of the images using the Matplotlib's `imgshow` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b02bb6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2, ncols=5,\n",
    "                     sharex=True, sharey=True)\n",
    "\n",
    "ax = ax.flatten()\n",
    "for i in range(10):\n",
    "    img = X_train[y_train == i][0].reshape(28, 28)\n",
    "    ax[i].imshow(img, cmap='Greys')\n",
    "\n",
    "ax[0].set_xticks([])\n",
    "ax[0].set_yticks([])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2615fd1",
   "metadata": {},
   "source": [
    "Cool, right !? Let's move on"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4b1bf9",
   "metadata": {},
   "source": [
    "Those NumPy arrays are big. At least, from the eyes of a begineer like me. Surely, there should be a way to compress and store those arrays so we avoid the overhead of reading and processing the data over and over.\n",
    "\n",
    "To achieve that, NumPy provides a function called `savez_compressed`. It saves several arrays into a single in compressed `.npz` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b52047d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed('mnist_scaled.npz',\n",
    "                   X_train=X_train,\n",
    "                   y_train=y_train,\n",
    "                   X_test=X_test,\n",
    "                   y_test=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37483283",
   "metadata": {},
   "source": [
    "After we create the `.npz` file, we can read it and load the preprocessed MNIST images using NumPy's `load` function. It goes like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d65957f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = np.load('mnist_scaled.npz')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e02a632",
   "metadata": {},
   "source": [
    "The `load` function returns an object with some attributes, \"**files**\" is one of them. The \"files\" attribute returns a list of the objects inside. It goes like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9ad4e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X_train', 'y_train', 'X_test', 'y_test']\n"
     ]
    }
   ],
   "source": [
    "print(mnist.files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8449fa4",
   "metadata": {},
   "source": [
    "Let's do a recap of what happened so far because what will follow is new and important for me:\n",
    "\n",
    "1. We downloaded the MNIST dataset. It's a 4-part dataset\n",
    "2. We unzipped the archives\n",
    "3. Read the dataset into Numpy arrays using the `load_mnist` helper we wrote\n",
    "4. We compressed the NumPy arrays using the `savez_compressed` function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc07949",
   "metadata": {},
   "source": [
    "Now, let's implement our MLP to classify those handwritten digits. This is what we are here for, right? So, buckle up ðŸ˜ŠðŸš€"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7319d8",
   "metadata": {},
   "source": [
    "### Implementing a multilayer perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df6a8be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "class NeuralNetMLP(object):\n",
    "    \"\"\"Feedforward neural network / Multi-layer perceptron classifier\n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "    n_hidden : int (default: 30)\n",
    "        Number of hidden units\n",
    "    \n",
    "    l2 : float (default: 0.)\n",
    "        Lambda value for L2-regularization\n",
    "        No regularization if l2=0. (default)\n",
    "    \n",
    "    epochs : int (default: 100)\n",
    "        Number of passes over the training set\n",
    "        \n",
    "    eta : float (default: 0.001)\n",
    "        Learning rate\n",
    "        \n",
    "    shuffle: bool (default: True)\n",
    "        Shuffles training data every epoch if \"True\" to prevent cycles\n",
    "        \n",
    "    minibatch_size : int (default: 1)\n",
    "        Number of training examples per batch. The number of training\n",
    "        examples to process before updating the weight. Remember the\n",
    "        definiton of \"batch\"\n",
    "        \n",
    "    seed : int (default: None)\n",
    "        Random seed for initializing weights and shuffling\n",
    "        \n",
    "    \n",
    "    Attributes\n",
    "    ------------\n",
    "    eval_ : dict\n",
    "        Dictionary of three arrays collecting the cost, training accuracy,\n",
    "        and validation accuracy (respectively) for each epoch during training\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_hidden=30, l2=0.,\n",
    "                 epochs=100, eta=0.001, shuffle=True, minibatch_size=1, seed=None):\n",
    "        \n",
    "        self.random = np.random.RandomState(seed)\n",
    "        self.n_hidden = n_hidden\n",
    "        self.l2 = l2\n",
    "        self.epochs = epochs\n",
    "        self.eta = eta\n",
    "        self.shuffle = shuffle\n",
    "        self.minibatch_size = minibatch_size\n",
    "        \n",
    "    def _oneshot(self, y, n_labels):\n",
    "        \"\"\"Encode labels into one-hot representation\n",
    "        \n",
    "        Parameters\n",
    "        -----------\n",
    "        y: array, shape = [n_examples]\n",
    "            Target values.\n",
    "        \n",
    "        n_labels: int\n",
    "            Number of labels. In our case, 10.\n",
    "            \n",
    "        Returns\n",
    "        ----------\n",
    "        oneshot: array, shape = (n_examples, n_labels)\n",
    "        \"\"\"\n",
    "        \n",
    "        onehot = np.zeros((n_labels, y.shape[0]))\n",
    "        for idx, val in enumerate(y.astype(int)):\n",
    "            onehot[val, idx] = 1\n",
    "        \n",
    "        return onehot.T\n",
    "    \n",
    "    def _sigmoid(self, z):\n",
    "        \"\"\"Compute logistic function (sigmoid)\"\"\"\n",
    "        return 1. / (1. + np.exp(-np.clip(z, -250, 250)))\n",
    "    \n",
    "    def _forward(self, X):\n",
    "        \"\"\"Compute forward propagation from input to output layer\"\"\"\n",
    "        \n",
    "        #1- Forward propagate from INPUT to HIDDEN layer\n",
    "        # \"Training matrix\" times \"weight matrix\"\n",
    "        # [n_examples, n_features] dot [n_features, n_hidden] -> [n_examples, n_hidden]\n",
    "        z_h = np.dot(X, self.w_h) + self.b_h\n",
    "        \n",
    "        #2- Apply activation function to hidden layer\n",
    "        a_h = self._sigmoid(z_h)\n",
    "        \n",
    "        #3- Forward propagate from HIDDEN to OUTPUT layer\n",
    "        #[n_examples, n_hidden] dot [n_hidden, n_classlabels] -> [n_examples, n_classlabels]\n",
    "        z_out = np.dot(a_h, self.w_out) + self.b_out\n",
    "        \n",
    "        #4- Apply activation function to output layer\n",
    "        a_out = self._sigmoid(z_out)\n",
    "        \n",
    "        return z_h, a_h, z_out, a_out\n",
    "    \n",
    "    def _compute_cost(self, y_enc, output):\n",
    "        \"\"\"Compute cost function\n",
    "        \n",
    "        Parameters\n",
    "        ------------\n",
    "        y_enc: array, shape = (n_examples, n_labels)\n",
    "            one-hot encoded class labels\n",
    "            \n",
    "        output: array, shape = [n_examples, n_output_units]\n",
    "            Activation of the output layer. Results from forward propagating from hidden to output layer\n",
    "            \n",
    "        Returns\n",
    "        ----------\n",
    "        cost : float\n",
    "            Regularized cost\n",
    "        \"\"\"\n",
    "        L2_term = (self.l2 * \n",
    "                   (np.sum(self.w_h ** 2.0) +\n",
    "                    np.sum(self.w_out ** 2.0)))\n",
    "        \n",
    "        term1 = -y_enc * (np.log(output))\n",
    "        term2 = (1.0 - y_enc) * np.log(1.0 - output)\n",
    "        cost = np.sum(term1 - term2) + L2_term\n",
    "        \n",
    "        return cost\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict class labels\n",
    "        \n",
    "        Parameters\n",
    "        ------------\n",
    "        X : array, shape = [n_examples, n_features]\n",
    "            Training set\n",
    "        \n",
    "        Returns\n",
    "        ------------\n",
    "        y_pred : array, shape = [n_examples]\n",
    "            Predicted class labels\n",
    "        \"\"\"\n",
    "        \n",
    "        z_h, a_h, z_out, a_out = self._forward(X)\n",
    "        y_pred = np.argmax(z_out, axis=1)\n",
    "        return y_pred\n",
    "    \n",
    "    def fit(self, X_train, y_train, X_valid, y_valid):\n",
    "        \"\"\" Learn weights from training data\n",
    "        \n",
    "        Parameters\n",
    "        ------------\n",
    "        X_train : array, shape = [n_examples, n_features]\n",
    "            Input layer with original features. It's our training set :)\n",
    "        y_train : array, shape = [n_examples]\n",
    "            Target class labels for each training example\n",
    "        X_valid : array, shape = [n_examples, n_features]\n",
    "            Part of the training set used for validation during training\n",
    "        y_valid : array, shape = [n_examples]\n",
    "            Target class labels for each training examples used for validation during training\n",
    "        \n",
    "        Returns\n",
    "        ------------\n",
    "        self\n",
    "        \n",
    "        \"\"\"\n",
    "        n_output = np.unique(y_train).shape[0] # no. of class labels. 10 in our case\n",
    "        n_features = X_train.shape[1] #784 features for each training example\n",
    "        \n",
    "        ########################\n",
    "        # Weight initialization\n",
    "        ########################\n",
    "        \n",
    "        #1- Weight matrix from input -> hidden layer\n",
    "        self.b_h = np.zeros(self.n_hidden)\n",
    "        self.w_h = self.random.normal(loc=0.0, scale=0.1, size=(n_features, self.n_hidden))\n",
    "        \n",
    "        #2- Weight matrix from hidden -> output layer\n",
    "        self.b_out = np.zeros(n_output)\n",
    "        self.w_out = self.random.normal(loc=0.0, scale=0.1, size=(self.n_hidden, n_output))\n",
    "        \n",
    "        ########################\n",
    "        # Some setup before training\n",
    "        ########################\n",
    "        \n",
    "        #1- for progr. format.\n",
    "        epoch_strlen = len(str(self.epochs))\n",
    "        \n",
    "        #2- collects the \"cost\", \"training\", and \"validation\" accuracy for each epoch\n",
    "        self.eval_ = {\n",
    "            'cost': [],\n",
    "            'train_acc': [],\n",
    "            'valid_acc': []\n",
    "        }\n",
    "        \n",
    "        #3- Hot encode training labels. Returns a \"n\" x 10 matrix\n",
    "        y_train_enc = self._oneshot(y_train, n_output)\n",
    "        \n",
    "        ########################\n",
    "        # Now training\n",
    "        ########################\n",
    "        for i in range(self.epochs):\n",
    "            #1- Generate an array of indices from 0 to X_train.shape[0] - 1 (n examples)\n",
    "            indices = np.arange(X_train.shape[0])\n",
    "            \n",
    "            #2- Shuffle the array\n",
    "            if self.shuffle:\n",
    "                self.random.shuffle(indices)\n",
    "                \n",
    "            #3- For each \"portion\" of the training set\n",
    "            for start_idx in range(0, indices.shape[0] - self.minibatch_size + 1, self.minibatch_size):\n",
    "                \n",
    "                #4- Select a range of indices from the \"indices\" array\n",
    "                batch_idx = indices[start_idx: start_idx + self.minibatch_size]\n",
    "                \n",
    "                #5- Forward propagate the training examples whose indices are in \"batch_idx\" through the NN\n",
    "                z_h, a_h, z_out, a_out = self._forward(X_train[batch_idx])\n",
    "                \n",
    "                ########################\n",
    "                # Backpropagation\n",
    "                ########################\n",
    "                \n",
    "                #6- The Delta out expression appears when taking\n",
    "                # the partial derivative of the loss function with respect to EACH \n",
    "                # weights in w_out and w_h. \n",
    "                # See my hand written work in \"etc\" folder.\n",
    "\n",
    "                #delta_out is a matrix [n_examples, n_classlabels]\n",
    "                delta_out = a_out - y_train_enc[batch_idx]\n",
    "\n",
    "                #7- The derivative of the activation with respect to z_h appears \n",
    "                # when taking partial derivatives of the loss function \n",
    "                # See my hand written work in \"etc\" folder.\n",
    "                #[n_examples, n_classlabels]\n",
    "                sigmoid_derivative_h = a_h * (1. - a_h)\n",
    "\n",
    "                #8- The delta_h exp appears when taking the derivative of the loss\n",
    "                # function with respect to weights in W_h\n",
    "                # [n_examples, n_classlabels] dot [n_classlabels, n_hidden] --> [n_examples, n_hidden]\n",
    "                delta_h = (np.dot(delta_out, self.w_out.T) * sigmoid_derivative_h)\n",
    "\n",
    "                #9- Compute the gradient of w_h\n",
    "                grad_w_h = np.dot(X_train[batch_idx].T, delta_h)\n",
    "                grad_b_h = np.sum(delta_h, axis=0)\n",
    "\n",
    "                #10- Compute the gradient of w_out\n",
    "                grad_w_out = np.dot(a_h.T, delta_out)\n",
    "                grad_b_out = np.sum(delta_out, axis=0)\n",
    "\n",
    "                #11- Regularization and weight updates\n",
    "                delta_w_h = (grad_w_h + self.l2*self.w_h)\n",
    "                delta_b_h = grad_b_h # bias is not regularized\n",
    "                self.w_h -= self.eta * delta_w_h\n",
    "                self.b_h -= self.eta * delta_b_h\n",
    "\n",
    "                delta_w_out = (grad_w_out + self.l2*self.w_out)\n",
    "                delta_b_out = grad_b_out # bias is not regularized\n",
    "                self.w_out -= self.eta * delta_w_out\n",
    "                self.b_out -= self.eta * delta_b_out\n",
    "\n",
    "            #############\n",
    "            # Evaluation\n",
    "            #############\n",
    "\n",
    "            #12- Forward propagate X_train through the network\n",
    "            z_h, a_h, z_out, a_out = self._forward(X_train)\n",
    "\n",
    "            #13- Compute the cost for this epoch\n",
    "            cost = self._compute_cost(y_enc=y_train_enc, output=a_out)\n",
    "\n",
    "            #14- \n",
    "            y_train_pred = self.predict(X_train)\n",
    "            y_valid_pred = self.predict(X_valid)\n",
    "\n",
    "            #15- Compute model accuracy on training and validation sets for this epoch\n",
    "            train_acc = ((np.sum(y_train == y_train_pred)).astype(np.float64) / X_train.shape[0])\n",
    "            valid_acc = ((np.sum(y_valid == y_valid_pred)).astype(np.float64) / X_valid.shape[0])\n",
    "\n",
    "            #16-\n",
    "            sys.stderr.write('\\r%0*d/%d | Cost: %.2f ' '| Train/Valid Acc.: %.2f%%/%.2f%% ' %(epoch_strlen, i+1, self.epochs, cost, train_acc*100, valid_acc*100))\n",
    "            sys.stderr.flush()\n",
    "\n",
    "            #17- \n",
    "            self.eval_['cost'].append(cost)\n",
    "            self.eval_['train_acc'].append(train_acc)\n",
    "            self.eval_['valid_acc'].append(valid_acc)\n",
    "        \n",
    "        return self"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "804cb474",
   "metadata": {},
   "source": [
    "Now, let's create an MLP. To classify our handwritten digits we will create an **784-100-10 MLP** which is an MLP with 784 input units (`n_features`), 100 hidden units(`n_hidden`), and 10 output units (`n_output`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a7c5545",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = NeuralNetMLP(n_hidden=100, l2=0.01, epochs=200, eta=0.0005, minibatch_size=100, shuffle=True, seed=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6c51cf31",
   "metadata": {},
   "source": [
    "With our shiny new MLP created, let's train it using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6df4731f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200/200 | Cost: 5065.78 | Train/Valid Acc.: 99.28%/97.98%  "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.NeuralNetMLP at 0x7f543a2c9820>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.fit( X_train=X_train[:55000],\n",
    "        y_train=y_train[:55000],\n",
    "        X_valid=X_train[55000:],\n",
    "        y_valid=y_train[55000:])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "69522e3b",
   "metadata": {},
   "source": [
    "With our training completed, let's plot the cost (i.e. error) over the 200 iterations (i.e. epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a50c501d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(nn.epochs), nn.eval_['cost'])\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Cost')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "79e0808a",
   "metadata": {},
   "source": [
    "As you can see, the cost during decreases substantially during the first 100 epoch, and seems to converge after it."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b86b7549",
   "metadata": {},
   "source": [
    "Now, Let's try to plot the accuracy on both the training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4397fb99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "40952425ce1129038402cc907e37f9a4c307be9e49316edd40e9084dac1145ab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
